{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression\n",
    "\n",
    "Why not MLE? They overfit.\n",
    "\n",
    "Why not MAP? the prior fits the overfitting, but no representation of uncertainty.\n",
    "ex: fit data to something (financial data), then have to predict value for new x. How certain are you? MAP doesn't say\n",
    "\n",
    "Bayesian approach gets you level of uncertainty. Optimize the appropriate loss function.\n",
    "\n",
    "gives us $p(y \\mid x, D) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "given data $D = [[x_1, y_1], ... [x_n, y_n]]$\n",
    "\n",
    "model: $y_1, ... y_n$ independent given $w, Y_i \\sim N(w^Tx_i, a^{-1})$\n",
    "\n",
    "$a$ is the precision $1/\\sigma^2$\n",
    "\n",
    "\n",
    "$w \\sim N(\\boldsymbol 0, b^{-1}I), b > 0$\n",
    "\n",
    "w is $w = (w_1, w_2, ... w_d)$, each is independent, i.i.d.\n",
    "\n",
    "Assume a, b are known. So $\\theta = w$, the only unknown.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To model nonlinearies in Xs\n",
    "\n",
    "\n",
    "Can replace $x_i$ by $\\Phi(x_i)$ for some basis function $\\Phi(x_i) = (\\Phi_1(x_1) ... \\Phi_n(x_i))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Posterior Distribution\n",
    "\n",
    "First need likelihood: $P(D|\\theta) = P(D|w) \\propto exp(-a/2(y-Aw)^T(y-Aw))$\n",
    "\n",
    "A is the design matrix:\n",
    "\n",
    "$$A =\\begin{bmatrix} x_1^T \\\\ \\vdots \\\\ x_n^T\\end{bmatrix}$$\n",
    "\n",
    "$y = (y_1, ... y_n)^T$\n",
    "\n",
    "\n",
    "Posterior is the prob of w given the data $P(w|D) \\propto p(D|w) P(w)\\, \\, \\,  (likelihood * prior )$\n",
    "\n",
    "$\\propto exp(-a/2(y-Aw)^T(y-Aw)-\\frac b 2 w^tw)$\n",
    "\n",
    "this is quadratic in w, so it is Gaussian:\n",
    "\n",
    "$$a(y-Aw)^T(y-Aw) =  bw^Tw = a(y^Ty - 2w^TA^Ty + w^TA^TAw) + bw^Tw \\\\\n",
    "= ay^Ty - 2sw^TA^Ty + w^T(aA^TA + bI)w \n",
    "$$\n",
    "\n",
    "Want to make this look like a gaussian. Gaussian, in general has $(w - \\mu)\\Lambda (w-\\mu) = w^T\\Lambda w - 2w^T\\Lambda \\mu + const$ Lambda is the precision matrix (inverse of covariance).\n",
    "\n",
    "$\\Lambda = aA^TA + bI$\n",
    "\n",
    "$$2sw^TA^Ty = w^T\\Lambda\\mu \\\\\n",
    "aA^Ty = \\Lambda \\mu \\\\\n",
    "\\mu = a\\Lambda^{-1}A^Ty \\\\\n",
    "\\Lambda = aA^TA + BI$$\n",
    "\n",
    "Therefore, posterior of w given data is\n",
    "$$p(w|D) = N(w, \\mu, \\Lambda^{-1}) \\\\\n",
    "\\mu = a\\Lambda^{-1}A^Ty \\\\\n",
    "\\Lambda = aA^TA + bI$$\n",
    "\n",
    "Aside, is precision matrix invertible? In form $B+cI$. Think of eigenvalues. $Bu =\\lambda u, cIu = cu$\n",
    "\n",
    "$(B+cI)u = Bu + cIu = \\lambda u + cu = (\\lambda + c)u$. If all eigenvalues are strictly positive, then it is invertible.\n",
    "\n",
    "\n",
    "### MAP estimate of w\n",
    "\n",
    "Given $p(w|D) = N(w, \\mu, \\Lambda^{-1})$, we can get MAP. MAP is maximum a posteriori, value of w that maximizes the posterior distribution. MAP for a Gaussian is just the mean (top of bell curve!)\n",
    "\n",
    "so, $w_{MAP} = \\mu = a(aA^TA + bI)^{-1}A^Ty = \\boxed{(A^TA + \\frac b a I)^{-1}A^Ty}$\n",
    "\n",
    "Compare to MLE:\n",
    "\n",
    "$w_{MLE} = (A^TA)^{-1}A^Ty = A^+ y$\n",
    "\n",
    "Difference is the $\\frac b a I$, which is the *regularization parameter*. this may not correspond to a proper prior, you may make it from an improper prior, so more general than Bayesian. \n",
    "\n",
    "\n",
    "If you go back to $\\propto exp(-a/2(y-Aw)^T(y-Aw)-\\frac b 2 w^tw)$, $\\frac b 2 w^tw$ is the regularization term. You are regularizing according to the squared norm of $w$.\n",
    "\n",
    "test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Distribution\n",
    "\n",
    "$p(y\\mid x, D)$. This is a *new* y that corresponds to a new $x$. \n",
    "\n",
    "In practice, use linear Gaussian models. But, to calculate ourselves:\n",
    "\n",
    "$p(y\\mid x, D) = \\int p(y \\mid x, D, w)p(w|x,D) dw$\n",
    "\n",
    "x is just notational, the x for the y, so\n",
    "\n",
    "$p(y \\mid x, D, w) = p(y \\mid x, w)$\n",
    "\n",
    "$p(w \\mid x, D) = p(w \\mid D)$\n",
    "\n",
    "Goal is to set $= \\int N(w \\mid ...) g(y) dw = g(y) \\propto N(y \\mid ...)$\n",
    "\n",
    "$$p(y\\mid \\mathbf x, D) = \\int N(y \\mid w^T\\mathbf x, a^{-1})N(w \\mid \\mu, \\Lambda^{-1}) dw \\\\\n",
    "\\propto \\int exp(-\\frac a 2 (y-w^T\\mathbf x)^2) exp(-\\frac 1 2 (w-\\mu)^T\\Lambda(w-\\mu))\\\\\n",
    "= \\int exp(-a/2 (y^2 - 2(w^T\\mathbf x)y + (w^T\\mathbf x)^2) - \\frac 1 2 (w^T\\Lambda w - 2w^T\\Lambda \\mu + \\mu^T\\Lambda\\mu))\n",
    "$$\n",
    "\n",
    "pull out 1/2, expression for exp is:\n",
    "\n",
    "$ay^2 - 2w^T\\mathbf xya + aw^T\\mathbf{xx}^Tw + w^T\\Lambda w - 2w^T\\Lambda\\mu$ (dropped constant $mu^T\\Lambda\\mu$)\n",
    "\n",
    "$= w^T(a\\mathbf{xx}^T + \\Lambda)w -2w^T(\\mathbf xya - \\Lambda\\mu) + ay^2$\n",
    "\n",
    "Now want to turn this into form gaussian form $(w-m)^TL(w-m) = w^TLw - 2w^TLm +m^TLm$.\n",
    "\n",
    "\n",
    "let $L = a\\mathbf{xx}^T + \\Lambda$\n",
    "\n",
    "$Lm = \\mathbf xya + \\Lambda \\mu$\n",
    "\n",
    "$m = L^{-1}(ay\\mathbf x + \\Lambda \\mu$ (assuming L inverse exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug in\n",
    "\n",
    "$$= w^TLw - 2w^TLm + m^TLm - m^TLm + ay^2 \\\\\n",
    "= (w-m)^TL(W-m) - m^TLm + ay^2$$\n",
    "\n",
    "\n",
    "$p(y \\mid x,D) \\propto \\int \\exp(-\\frac 1 2 (w-m)^TL(w-m)) \\times \\exp(frac 1 2 m^TLm - \\frac 1 2 ay^2) dw \\\\\n",
    "\\propto \\exp(\\frac 1 2 m^TLm - \\frac 1 2 ay^2)$. \n",
    "\n",
    "this is g(y). Now rearrange to look like a normal!\n",
    "\n",
    "$ay^2 - m^TLm$\n",
    "\n",
    "$$m^TLm = (ay\\mathbf x + \\Lambda\\mu)^TL^{-1}LL^{-1}(ay\\mathbf x + \\Lambda\\mu) \\\\\n",
    "= ay\\mathbf x^TL^{-1}(ay\\mathbf x) + 2ay\\mathbf x^TL^{-1}\\Lambda \\mu + \\mu^TL^{-1}\\Lambda \\mu \\\\\n",
    "= (a^2\\mathbf x^TL^{-1}x)y^2 + 2(a\\mathbf x^TL^{-1}\\Lambda \\mu) y + const $$\n",
    "\n",
    "So,\n",
    "\n",
    "$$ay^2 - m^TLm = (a - a^2\\mathbf x^TL^{-1}x)y^2 - 2(a\\mathbf x^TL^{-1}\\Lambda \\mu) y +c $$\n",
    "\n",
    "let $\\lambda = a(1-ax^TL^{-1}x)$\n",
    "\n",
    "$u = \\frac 1 \\lambda ax^TL^{-1}\\Lambda \\mu$\n",
    "\n",
    "$$ p(y \\mid \\mathbf x, D) \\propto \\exp(- \\frac \\lambda 2(y-u)^2)$$\n",
    "\n",
    "\n",
    "Can clean up:\n",
    "\n",
    "$\\boxed{u = \\mu^Tx \\\\  \\\\\n",
    "\\frac 1 \\lambda = \\frac 1 a + \\mathbf x^T\\Lambda^{-1} \\mathbf x \\\\\n",
    "p(y \\mid \\mathbf x,D) = N(y \\mid u, \\frac 1 \\lambda)}$\n",
    "\n",
    "So, it is a Gaussian!!!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show value for $\\lambda$:\n",
    "\n",
    "$$L^{-1} = (axx^T + \\Lambda)^{-1}$$\n",
    "\n",
    "Use Sherman Morrison Theorem.\n",
    "\n",
    "$$L^{-1} = \\Lambda^{-1} - \\frac{\\Lambda^{-1}axx^T\\Lambda^{-1}}{1+ax^T\\Lambda^{-1}x}$$\n",
    "\n",
    "$$x^T\\Lambda^{-1}x = \\alpha - \\frac{a\\alpha^2}{1+a\\alpha} = \\frac{\\alpha + a\\alpha^2 - a\\alpha^2}{1+a\\alpha}$$\n",
    "\n",
    "$$\\lambda = a(1-a\\frac{a\\alpha}{1+a\\alpha}) = \\frac{a}{1+a\\alpha}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu^Tx = \\frac 1 \\lambda ax^TL^{-1}\\Lambda \\mu = \\mu^T \\frac 1 \\lambda ax^TL^{-1}\\Lambda\n",
    "$$\n",
    "\n",
    "$$\\mathbf x = \\frac 1 \\lambda ax^TL^{-1}\\Lambda$$\n",
    "\n",
    "$$L \\Lambda^{-1}x = \\frac 1 \\lambda a \\mathbf x\\\\\n",
    "(axx^T + \\Lambda)\\Lambda^{-1}x = axx^T\\Lambda^{-1}x + x = (a\\alpha + 1)x$$\n",
    "\n",
    "$$\\frac 1 \\lambda = \\frac{a\\alpha + 1}{\\alpha}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
